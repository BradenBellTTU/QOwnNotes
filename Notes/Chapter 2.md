Chapter 2
========================
### What makes one algorithm "better" than another?
+ Simplicity
+ Generality (can it solve a larger range of problems?)
+ Run time
+ Memory usage


### How to measure runtime?
+ Most algorithms run longer on larger input sizes

+ How should we measure input size?
    + Sorting a list of *n* elements
    + Evaluating a polynomial (measured in the degree of the polynomial)
    + Adding two *n* x *n* matrices (the number of rows or columns or total number of elements)
    + Determine if *p* is prime



### Space and Time Complexity
+ **Space Complexity** - 
+ **Time complexity** -
+ What do we measure?
    + Time
        + Clock time
            + Seconds
            + Minutes
            + Hours
        + Operations
            + Basic operations


### Worst Case Efficiency
+ **Definition** - The worst-case efficiency is the largest amount of time (or memory) required to solve a given problem size
    + **Examples**:
        + Searching a list size of *n*
        + Adding two *n* x *n* matricies

### Average Case Efficiency
+ **Definition** - the average amount of time...?
    + **Example:**
        + Let *L* be an unsorted list of *n* items. Suppose *p* the probability of a successful search of *L* (the item is found), where 0 <= *p* <= 1. Also suppose that probability of a match occuring at the *i* th location in the list *L* is the same for every *i*.

### Amortized Efficiency
+ **Definition** - refers to the cost of performing a sequence of aggregated operations, as opposed to performing them individually